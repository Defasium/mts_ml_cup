{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ограничения на ресурсы для numpy, импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\" # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"6\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"6\" # export NUMEXPR_NUM_THREADS=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import QuantileTransformer, Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по регионам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 79)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/region_name_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "\n",
    "reg_id = np.array(regmap['data'].argmax(axis=1)).flatten()\n",
    "pd.Series(\n",
    "    reg_id\n",
    ").value_counts().head(50).index\n",
    "\n",
    "_id_label, _id_cnt = np.unique(reg_id, return_counts=True)\n",
    "_id_map = {}\n",
    "regionmap = csr_matrix(regmap['data'][:, _id_label[_id_cnt>20]])\n",
    "print(regionmap.shape)\n",
    "for cid in _id_label[_id_cnt>20]:\n",
    "    _id_map[cid] = len(_id_map)\n",
    "reg_id = np.array([_id_map.get(cid, len(_id_map)) for cid in reg_id])\n",
    "del _id_label, _id_cnt, _id_map\n",
    "reg_id.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по городам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 661)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/city_name_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "\n",
    "city_id = np.array(regmap['data'].argmax(axis=1)).flatten()\n",
    "pd.Series(\n",
    "    city_id\n",
    ").value_counts().head(50).index\n",
    "\n",
    "_id_label, _id_cnt = np.unique(city_id, return_counts=True)\n",
    "_id_map = {}\n",
    "citmap = csr_matrix(regmap['data'][:, _id_label[_id_cnt>20]])\n",
    "print(citmap.shape)\n",
    "for cid in _id_label[_id_cnt>20]:\n",
    "    _id_map[cid] = len(_id_map)\n",
    "city_id = np.array([_id_map.get(cid, len(_id_map)) for cid in city_id])\n",
    "del _id_label, _id_cnt, _id_map\n",
    "city_id.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по производителю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/cpe_manufacturer_name_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "\n",
    "cpeman_id = np.array(regmap['data'].argmax(axis=1)).flatten()\n",
    "pd.Series(\n",
    "    cpeman_id\n",
    ").value_counts().head(50).index\n",
    "\n",
    "_id_label, _id_cnt = np.unique(cpeman_id, return_counts=True)\n",
    "_id_map = {}\n",
    "cpemanmap = csr_matrix(regmap['data'][:, _id_label[_id_cnt>20]])\n",
    "print(cpemanmap.shape)\n",
    "for cid in _id_label[_id_cnt>20]:\n",
    "    _id_map[cid] = len(_id_map)\n",
    "cpeman_id = np.array([_id_map.get(cid, len(_id_map)) for cid in cpeman_id])\n",
    "del _id_label, _id_cnt, _id_map\n",
    "cpeman_id.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по устройству"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 396)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/cpe_model_name_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "\n",
    "cpemodname_id = np.array(regmap['data'].argmax(axis=1)).flatten()\n",
    "pd.Series(\n",
    "    cpemodname_id\n",
    ").value_counts().head(50).index\n",
    "\n",
    "_id_label, _id_cnt = np.unique(cpemodname_id, return_counts=True)\n",
    "_id_map = {}\n",
    "cpemodnamemap = csr_matrix(regmap['data'][:, _id_label[_id_cnt>20]])\n",
    "print(cpemodnamemap.shape)\n",
    "for cid in _id_label[_id_cnt>20]:\n",
    "    _id_map[cid] = len(_id_map)\n",
    "cpemodname_id = np.array([_id_map.get(cid, len(_id_map)) for cid in cpemodname_id])\n",
    "del _id_label, _id_cnt, _id_map\n",
    "cpemodname_id.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по cpe_type_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 2, 1, 3], dtype='int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/cpe_type_cd_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "\n",
    "cpetype_id = np.array(regmap['data'].argmax(axis=1)).flatten()\n",
    "cpetypemap = csr_matrix(regmap['data'])\n",
    "print(cpetypemap.shape)\n",
    "pd.Series(\n",
    "    cpetype_id\n",
    ").value_counts().head(50).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по датам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 397)\n",
      "(415317, 203)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/date_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "    \n",
    "date_id = np.array(regmap['data'].argmax(axis=1)).flatten()\n",
    "datemap = csr_matrix(regmap['data'])\n",
    "print(datemap.shape)\n",
    "pd.Series(\n",
    "    date_id\n",
    ").value_counts().tail(50)\n",
    "\n",
    "_id_label, _id_cnt = np.unique(date_id, return_counts=True)\n",
    "_id_map = {}\n",
    "datemap = csr_matrix(regmap['data'][:, _id_label[_id_cnt>20]])\n",
    "print(datemap.shape)\n",
    "for cid in _id_label[_id_cnt>20]:\n",
    "    _id_map[cid] = len(_id_map)\n",
    "date_id = np.array([_id_map.get(cid, len(_id_map)) for cid in date_id])\n",
    "del _id_label, _id_cnt, _id_map\n",
    "date_id.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по времени суток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    217543\n",
       "2    126023\n",
       "0     64969\n",
       "3      6782\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/part_of_day_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "\n",
    "pod_id = np.array(regmap['data'].argmax(axis=1)).flatten()\n",
    "podmap = csr_matrix(regmap['data'])\n",
    "print(podmap.shape)\n",
    "pd.Series(\n",
    "    pod_id\n",
    ").value_counts().tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по ценам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('files/price_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    regmap = pickle.load(f)\n",
    "\n",
    "prices = np.array(pd.read_csv('files/price_mapper.tsv.gz', sep='\\t').price.fillna(20_000).tolist()\n",
    "                  + [20_000])\n",
    "price_id = regmap['data']\n",
    "price_id = (price_id.dot(prices)/np.array(price_id.sum(axis=1)).flatten())\n",
    "pricemap_id = regmap['data'].dot(KBinsDiscretizer(n_bins=31,\n",
    "                                                  strategy='kmeans',).fit_transform(prices[:, None]**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка мешка слов по ссылкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': <415317x199684 sparse matrix of type '<class 'numpy.uint32'>'\n",
       " \twith 32277669 stored elements in Compressed Sparse Row format>,\n",
       " 'uids': array([     4,     16,     18, ..., 415276, 415288, 415293])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('files/url_host_cbag_v2.pickle.gz', 'rb') as f:\n",
    "    datamap = pickle.load(f)\n",
    "datamap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка признаков тайтлов ссылок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<415317x13118 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 82784390 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('auxilary/domain20k_title.pickle.gz', 'rb') as f:\n",
    "    titlemap = pickle.load(f)\n",
    "\n",
    "map_df = pd.read_csv('auxilary/url_host_mapper_v2.tsv.gz', sep='\\t')\n",
    "\n",
    "titlemap = \\\n",
    "datamap['data'][:, pd.DataFrame(\n",
    "    dict(url_host=titlemap['domain'])\n",
    "        ).merge(map_df).url_host_idx.values\n",
    "               ].dot(CountVectorizer(ngram_range=(1,2),\n",
    "                                     min_df=2,).\\\n",
    "                     fit_transform(titlemap['title']))\n",
    "\n",
    "titlemap = csr_matrix((np.log2(1+titlemap.data), titlemap.nonzero()),\n",
    "                      shape=titlemap.shape, dtype=np.float32)\n",
    "titlemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка эмбеддингов скриншотов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415317, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('auxilary/clipVIT_scores_20k.pickle.gz', 'rb') as f:\n",
    "    clipmap = pickle.load(f)\n",
    "\n",
    "clipmap = \\\n",
    "TfidfTransformer(sublinear_tf=True, norm=None).\\\n",
    "    fit_transform(\n",
    "        datamap['data'][:, pd.DataFrame(\n",
    "            dict(url_host=clipmap['domains'])\n",
    "                ).merge(map_df).url_host_idx.values\n",
    "                       ]\n",
    "    ).\\\n",
    "    dot(\n",
    "        np.array(clipmap['scores'])\n",
    "    )\n",
    "\n",
    "clipmap = Normalizer().fit_transform(clipmap)\n",
    "clipmap = np.float32(clipmap)\n",
    "\n",
    "clipmap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка признаков Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут не сконкатенированные по 4 доменам эмбеддинги, а только по url_host\n",
    "with gzip.open('doc2vec_feats_128.pickle.gz', 'rb') as f:\n",
    "    doc2vec_feats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение частотных ссылок мешка слов url_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_mask = (np.array((datamap['data']>0).sum(axis=0)).flatten() > 40)\n",
    "feats_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считывание файла с таргетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>135832</td>\n",
       "      <td>112198</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154409</td>\n",
       "      <td>297298</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80640</td>\n",
       "      <td>390344</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387027</td>\n",
       "      <td>131868</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160476</td>\n",
       "      <td>357784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270408</td>\n",
       "      <td>211076</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379821</td>\n",
       "      <td>58745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307483</td>\n",
       "      <td>164654</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391925</td>\n",
       "      <td>181328</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207270</td>\n",
       "      <td>409909</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id   age  is_male\n",
       "135832   112198  40.0      1.0\n",
       "154409   297298  51.0      0.0\n",
       "80640    390344  66.0      0.0\n",
       "387027   131868  42.0      0.0\n",
       "160476   357784  51.0      1.0\n",
       "270408   211076  32.0      1.0\n",
       "379821    58745   NaN      NaN\n",
       "307483   164654  55.0      1.0\n",
       "391925   181328  42.0      1.0\n",
       "207270   409909  24.0      1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_df = pd.read_csv('target.tsv.gz', sep='\\t')\n",
    "trg_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка таргетов и поднабора юзеров из обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'data'\n",
    "\n",
    "(trg_df.age.isna()|trg_df.is_male.isna()).sum(),\\\n",
    "\n",
    "all_mask = (~trg_df.age.isna()|~trg_df.is_male.isna()).values.copy()\n",
    "trg_train = trg_df[all_mask].fillna({'is_male': 0.5, 'age':34})\n",
    "trg_age = trg_train.age.values.copy()\n",
    "trg_sex = trg_train.is_male.values.copy()\n",
    "\n",
    "\n",
    "age_bins = [[0, 25], [26, 35], [36, 45], [46, 55], [56, 65], [66, 999]]\n",
    "\n",
    "print('Train sample:', all_mask.sum())\n",
    "\n",
    "y_all = 0\n",
    "for k, age_bin in enumerate(age_bins):\n",
    "    y = pd.Series(trg_age).between(*age_bin).values.copy()\n",
    "    y_all += y*(k+1)\n",
    "\n",
    "X_tr = datamap[key][all_mask][:, feats_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение мешков слов второстепенных доменов в один"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000, 1407)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbag_all = hstack([regionmap,\n",
    "                   citmap,\n",
    "                   cpemanmap,\n",
    "                   cpemodnamemap,\n",
    "                   cpetypemap,\n",
    "                   podmap,\n",
    "                   datemap,\n",
    "                   pricemap_id\n",
    "                  ])\n",
    "cbag_all = QuantileTransformer(n_quantiles=10).fit_transform(cbag_all)\n",
    "cbag_all = csr_matrix(cbag_all)\n",
    "cbag_all_train = cbag_all[all_mask]\n",
    "cbag_all_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переобозначения обучающих поднаборов признаков ради удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270000, 128)\n",
      "(270000, 768)\n",
      "(270000, 13118)\n"
     ]
    }
   ],
   "source": [
    "doc2vec_feats_train = doc2vec_feats[all_mask].copy()\n",
    "print(doc2vec_feats_train.shape)\n",
    "clipmap_train = clipmap[all_mask].copy()\n",
    "print(clipmap_train.shape)\n",
    "titlemap = csr_matrix(titlemap, dtype=np.float32)\n",
    "titlemap_train = titlemap[all_mask]\n",
    "print(titlemap_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка мешка слов ссылок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = datamap[key][:, feats_mask]\n",
    "all_data_sqrt = csr_matrix((all_data.data**0.5, all_data.nonzero()),\n",
    "                     shape=all_data.shape,\n",
    "                     dtype=np.float32)\n",
    "del all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройка валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "kfold = StratifiedKFold(n_splits=10,\n",
    "                        shuffle=True,\n",
    "                        random_state=RANDOM_SEED)\n",
    "folds = [(train_ind, test_ind) for train_ind, test_ind in\n",
    "         kfold.split((np.uint8(trg_sex*2)+y_all*10).astype(str),\n",
    "                     (np.uint8(trg_sex*2)+y_all*10).astype(str))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция с архитектурой модели (старая версия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_all(emb_size=8, dense_size=512, l1_reg=1e-7,\n",
    "                  base_lr=2e-4, sex_weight=1, age_weight=1,\n",
    "                  return_sex_feats=False,\n",
    "                  **kwargs):\n",
    "    l1reg = tf.keras.regularizers.l1(l1_reg)\n",
    "\n",
    "    # urls\n",
    "    inp = tf.keras.layers.Input((X_tr.shape[1],), sparse=False)\n",
    "    x = inp\n",
    "    x = tf.keras.layers.Dense(dense_size, activation='relu',\n",
    "                              use_bias=False,\n",
    "                              kernel_regularizer=l1reg)(x)\n",
    "\n",
    "    use_feats = kwargs['use_feats']\n",
    "\n",
    "    # region id\n",
    "    inp2 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x2 = tf.keras.layers.Embedding(reg_id.max()+1,\n",
    "                                   kwargs.get('e_region', emb_size),\n",
    "                                   embeddings_regularizer=l1reg)(inp2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    # city id\n",
    "    inp3 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x3 = tf.keras.layers.Embedding(city_id.max()+1,\n",
    "                                   kwargs.get('e_city', emb_size),\n",
    "                                   embeddings_regularizer=l1reg)(inp3)\n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "\n",
    "    # cpeman id\n",
    "    inp4 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x4 = tf.keras.layers.Embedding(cpeman_id.max()+1,\n",
    "                                   kwargs.get('e_cpeman', emb_size),\n",
    "                                   embeddings_regularizer=l1reg)(inp4)\n",
    "    x4 = tf.keras.layers.Flatten()(x4)\n",
    "\n",
    "    # cpemodname id\n",
    "    inp5 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x5 = tf.keras.layers.Embedding(cpemodname_id.max()+1,\n",
    "                                   kwargs.get('e_cpemodname', emb_size),\n",
    "                                   embeddings_regularizer=l1reg)(inp5)\n",
    "    x5 = tf.keras.layers.Flatten()(x5)\n",
    "\n",
    "    # cpetype_id id\n",
    "    inp6 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x6 = tf.keras.layers.Embedding(cpetype_id.max()+1,\n",
    "                                   kwargs.get('e_cpetype', emb_size),\n",
    "                                   embeddings_regularizer=l1reg)(inp6)\n",
    "    x6 = tf.keras.layers.Flatten()(x6)\n",
    "\n",
    "    # price id\n",
    "    inp7 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x7 = tf.keras.layers.Dense(kwargs.get('e_price', emb_size),\n",
    "                               activation='tanh',\n",
    "                               kernel_regularizer=l1reg)(inp7)\n",
    "\n",
    "    # cbagmap\n",
    "    inp8 = tf.keras.layers.Input((cbag_all.shape[-1],), sparse=False)\n",
    "    x8 = tf.keras.layers.Dense(kwargs.get('e_cbag', emb_size*2),\n",
    "                               activation='relu',\n",
    "                               kernel_regularizer=l1reg)(inp8)\n",
    "\n",
    "    # date_id id\n",
    "    inp9 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x9 = tf.keras.layers.Embedding(date_id.max()+1,\n",
    "                                   kwargs.get('e_date', emb_size),\n",
    "                                   embeddings_regularizer=l1reg)(inp9)\n",
    "    x9 = tf.keras.layers.Flatten()(x9)\n",
    "\n",
    "    # pod_id id\n",
    "    inp10 = tf.keras.layers.Input((1,), sparse=False)\n",
    "    x10 = tf.keras.layers.Embedding(pod_id.max()+1,\n",
    "                                    kwargs.get('e_pod', emb_size),\n",
    "                                    embeddings_regularizer=l1reg)(inp10)\n",
    "    x10 = tf.keras.layers.Flatten()(x10)\n",
    "\n",
    "    # d2v\n",
    "    inp13 = tf.keras.layers.Input((doc2vec_feats.shape[-1],), sparse=False)\n",
    "    #x13 = tf.keras.layers.Dense(emb_size, activation='relu',\n",
    "    #                            kernel_regularizer=l1reg)(inp13)\n",
    "    x13 = inp13\n",
    "\n",
    "    # clip\n",
    "    inp14 = tf.keras.layers.Input((clipmap_train.shape[-1],), sparse=False)\n",
    "    #x14 = tf.keras.layers.Dense(emb_size, activation='relu',\n",
    "    #                            kernel_regularizer=l1reg)(inp14)\n",
    "    x14 = inp14\n",
    "\n",
    "    # titles\n",
    "    inp15 = tf.keras.layers.Input((titlemap_train.shape[-1],), sparse=False)\n",
    "    x15 = tf.keras.layers.Dense(kwargs.get('e_title', emb_size*2),\n",
    "                                activation='relu',\n",
    "                                use_bias=False,\n",
    "                                kernel_regularizer=l1reg)(inp15)\n",
    "\n",
    "    x_extra = [\n",
    "                 x2,\n",
    "                 x3,\n",
    "                 x4,\n",
    "                 x5,\n",
    "                 x6,\n",
    "                 x7,\n",
    "                 x8,\n",
    "                 x9,\n",
    "                 x10,\n",
    "                 x13,\n",
    "                 x14,\n",
    "                 x15\n",
    "            ]\n",
    "\n",
    "    x_extra = [xx for xx, remain in zip(x_extra, use_feats) if remain]\n",
    "\n",
    "    x_sex0 = tf.keras.layers.concatenate([x] + x_extra)\n",
    "    x_age0 = x_sex0\n",
    "\n",
    "    parallel_age = []\n",
    "\n",
    "    for _ in range(1):\n",
    "        prev_x_age = [x_age0]\n",
    "        x_age = x_age0\n",
    "        for _ in range(2):\n",
    "            x2 = tf.keras.layers.Dense(x_age.shape[-1], activation='relu',\n",
    "                                       use_bias=True,\n",
    "                                       kernel_regularizer=l1reg)(x_age)\n",
    "            # dense connections\n",
    "            prev_x_age.append(x2)\n",
    "            x_age = tf.keras.layers.add(prev_x_age)\n",
    "        parallel_age.append(x_age)\n",
    "\n",
    "    if kwargs.get('age_extra_dim', False):\n",
    "        x_age = tf.keras.layers.concatenate([\n",
    "            tf.keras.layers.Dense(kwargs.get('age_extra_dim'),\n",
    "                                  activation='relu',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_regularizer=l1reg)(x_age0)\n",
    "        ] + parallel_age)\n",
    "    else:\n",
    "        x_age = parallel_age[0]\n",
    "\n",
    "    if kwargs.get('sex_extra_dim', False):\n",
    "        x_sex = tf.keras.layers.concatenate([\n",
    "            tf.keras.layers.Dense(kwargs.get('sex_extra_dim'),\n",
    "                                  activation='relu',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_regularizer=l1reg)(x_sex0)\n",
    "        ] + parallel_age)\n",
    "    else:\n",
    "        x_sex = parallel_age[0]\n",
    "\n",
    "    out1 = tf.keras.layers.Dense(1, activation='sigmoid', use_bias=True, name='sex',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(l1_reg))(x_sex)\n",
    "\n",
    "    out2 = tf.keras.layers.Dense(6, activation='softmax', use_bias=True, name='age',\n",
    "                            kernel_regularizer=tf.keras.regularizers.l1(l1_reg))(x_age)\n",
    "\n",
    "    inps_extra = [\n",
    "        inp2,\n",
    "        inp3,\n",
    "        inp4,\n",
    "        inp5,\n",
    "        inp6,\n",
    "        inp7,\n",
    "        inp8,\n",
    "        inp9,\n",
    "        inp10,\n",
    "        inp13,\n",
    "        inp14,\n",
    "        inp15,\n",
    "    ]\n",
    "    inps_extra = [xx for xx, remain in zip(inps_extra, use_feats) if remain]\n",
    "\n",
    "    output_layers = [out1, out2]\n",
    "    if return_sex_feats:\n",
    "        output_layers.append(x_sex)\n",
    "    model = tf.keras.models.Model([inp] + inps_extra, output_layers)\n",
    "    model.compile(loss={'sex':'binary_crossentropy',\n",
    "                        'age':'categorical_crossentropy'},\n",
    "                  loss_weights={'sex':sex_weight, 'age':age_weight},\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=base_lr,\n",
    "                                                     clipvalue=2),\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_scheduler(base_lr=2e-4, factor=1., offset=0.5):\n",
    "    def scheduler(epoch, lr):\n",
    "        return base_lr*10**(-epoch*factor+offset)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция-генератор фолдов для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = csr_matrix((X_tr.data**0.5, X_tr.nonzero()),\n",
    "                    shape=X_tr.shape,\n",
    "                    dtype=np.float32)\n",
    "\n",
    "y_ohe_age = np.zeros((y_all.size, y_all.max()))\n",
    "y_ohe_age[np.arange(y_all.size), y_all-1] = 1.\n",
    "\n",
    "def generate_folds(folds):\n",
    "    for k, (train_ind, test_ind) in enumerate(tqdm(folds)):\n",
    "        train_dat = X_train[train_ind]\n",
    "        train_y_sex = trg_sex[train_ind]\n",
    "        train_y_age = y_ohe_age[train_ind]\n",
    "        val_dat = X_train[test_ind]\n",
    "        val_y_sex = trg_sex[test_ind]\n",
    "        val_y_age = y_ohe_age[test_ind]\n",
    "\n",
    "        train_aux_dat = [train_dat,\n",
    "                         reg_id[all_mask][train_ind, None],\n",
    "                         city_id[all_mask][train_ind, None],\n",
    "                         cpeman_id[all_mask][train_ind, None],\n",
    "                         cpemodname_id[all_mask][train_ind, None],\n",
    "                         cpetype_id[all_mask][train_ind, None],\n",
    "                         price_id[all_mask][train_ind, None]**0.5,\n",
    "                         cbag_all_train[train_ind],\n",
    "                         date_id[all_mask][train_ind, None],\n",
    "                         pod_id[all_mask][train_ind, None],\n",
    "                         doc2vec_feats_train[train_ind],\n",
    "                         clipmap_train[train_ind],\n",
    "                         titlemap_train[train_ind],\n",
    "                        ]\n",
    "\n",
    "        val_aux_dat = [val_dat,\n",
    "                       reg_id[all_mask][test_ind, None],\n",
    "                       city_id[all_mask][test_ind, None],\n",
    "                       cpeman_id[all_mask][test_ind, None],\n",
    "                       cpemodname_id[all_mask][test_ind, None],\n",
    "                       cpetype_id[all_mask][test_ind, None],\n",
    "                       price_id[all_mask][test_ind, None]**0.5,\n",
    "                       cbag_all_train[test_ind],\n",
    "                       date_id[all_mask][test_ind, None],\n",
    "                       pod_id[all_mask][test_ind, None],\n",
    "                       doc2vec_feats_train[test_ind],\n",
    "                       clipmap_train[test_ind],\n",
    "                       titlemap_train[test_ind],\n",
    "                      ]\n",
    "\n",
    "        # использую скоры логрега для первоначальной самодистилляции\n",
    "        model_lr = \\\n",
    "        Pipeline([('tfidf', TfidfTransformer(sublinear_tf=True, norm='l2')),\n",
    "                  ('model', LogisticRegression(C=1.5,\n",
    "                                               penalty='l1',\n",
    "                                               solver='liblinear',\n",
    "                                               #class_weight='balanced',\n",
    "                                               max_iter=5,\n",
    "                                               dual=False)\n",
    "                    )])\n",
    "        scores_lr = cross_val_predict(model_lr,\n",
    "                                      train_dat,\n",
    "                                      train_y_age.argmax(axis=1),\n",
    "                                      cv=5,\n",
    "                                      method='predict_proba',\n",
    "                                      n_jobs=5)\n",
    "\n",
    "        # только для скоров возраста, для пола дистилляция от логрега ухудшает качество\n",
    "        alpha = 0.1\n",
    "        train_y_age = train_y_age*(1-alpha)+scores_lr*alpha\n",
    "\n",
    "        yield [[train_aux_dat, [train_y_sex, train_y_age]],\n",
    "               [val_aux_dat, [val_y_sex, val_y_age]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мапка признаков для удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat2idx_map = dict(e_region=0,\n",
    "                    e_city=1,\n",
    "                    e_cpeman=2,\n",
    "                    e_cpemodname=3,\n",
    "                    e_cpetype=4,\n",
    "                    e_price=5,\n",
    "                    e_date=6,\n",
    "                    e_pod=7,\n",
    "                    e_cbag=8,\n",
    "                    e_doc=9,\n",
    "                    e_clip=10,\n",
    "                    e_title=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфигурация архитектуры нейронной сети для получения oof скоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = \\\n",
    "{'age_extra_dim': 22,\n",
    " 'age_weight': 1.8,\n",
    " 'base_lr': 0.0017782794100389228,\n",
    " 'batch_size': 256,\n",
    " 'dense_size': 2048,\n",
    " 'e_cbag': 362,\n",
    " 'e_clip': 1,\n",
    " 'e_cpeman': 53,\n",
    " 'e_cpemodname': 1,\n",
    " 'e_cpetype': 8,\n",
    " 'e_price': 38,\n",
    " 'emb_size': 11,\n",
    " 'epochs': 3,\n",
    " 'factor': 1.25,\n",
    " 'offset': -0.5,\n",
    " 'sex_weight': 1.5,\n",
    " 'steps_subsample': 1.0,\n",
    " 'use_feats': [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для получения oof скоров для каждого разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_score(args):\n",
    "    # delete useless values\n",
    "    for k, v in args.copy().items():\n",
    "        if v is None:\n",
    "            del args[k]\n",
    "            continue\n",
    "        if k.startswith('e_') or 'extra' in k:\n",
    "            args[k] = int(args[k])\n",
    "\n",
    "    use_feats = [1 for _ in range(len(feat2idx_map))]\n",
    "    for k, v in feat2idx_map.items():\n",
    "        use_feats[v] = int(args.get(k, 100) != 1)\n",
    "\n",
    "    args['use_feats'] = tuple(use_feats)\n",
    "\n",
    "    epochs = args['epochs'] = int(args['epochs']) #4\n",
    "    batch_size = args['batch_size'] = int(args['batch_size']) #128+256\n",
    "    steps_subsample = args['steps_subsample'] = float('%.3f'%args['steps_subsample']) #0.95\n",
    "    base_lr = args['base_lr'] = args['base_lr'] #2e-4\n",
    "    factor = args['factor'] = float('%.3f'%args['factor']) #1.\n",
    "    offset = args['offset'] = float('%.3f'%args['offset']) #0.5\n",
    "    emb_size = args['emb_size'] = int(args['emb_size']) # 64\n",
    "    dense_size = args['dense_size'] = int(args['dense_size']) #1024\n",
    "    sex_weight = args['sex_weight'] = float('%.3f'%args['sex_weight'])\n",
    "    age_weight = args['age_weight'] = float('%.3f'%args['age_weight'])\n",
    "    scheduler = get_scheduler(base_lr, factor, offset)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    K = 1\n",
    "    for cache, (train_ind, test_ind) in zip(generate_folds(folds), tqdm(folds)):\n",
    "        [train_aux_dat, train_y],\\\n",
    "        [val_aux_dat, val_y] = cache\n",
    "        train_y_sex, train_y_age = train_y\n",
    "        val_y_sex, val_y_age = val_y\n",
    "\n",
    "        train_aux_dat = [xx for xx, remain in zip(train_aux_dat, [1]+use_feats) if remain]\n",
    "        val_aux_dat = [xx for xx, remain in zip(val_aux_dat, [1]+use_feats) if remain]\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=5,\n",
    "                        shuffle=True,\n",
    "                        random_state=RANDOM_SEED)\n",
    "        folds_inner = [(inner_train_ind, inner_test_ind) for inner_train_ind, inner_test_ind in\n",
    "                 kfold.split(train_y_sex,\n",
    "                             (np.uint8(train_y_sex*2)+train_y_age.argmax(axis=1)*10).astype(str))]\n",
    "\n",
    "        oof_scores_sex = np.zeros(train_y_sex.shape)\n",
    "        oof_scores_age = np.zeros(train_y_age.shape)\n",
    "        for inner_train_ind, inner_test_ind in tqdm(folds_inner):\n",
    "\n",
    "            model_nn = get_model_all(l1_reg=1e-7, **args)\n",
    "\n",
    "            st_time = time.time()\n",
    "\n",
    "            model_nn.fit([xx[inner_train_ind] for xx in train_aux_dat],\n",
    "                         [yy[inner_train_ind] for yy in train_y],\n",
    "                      batch_size=batch_size,\n",
    "                      steps_per_epoch=int(steps_subsample*inner_train_ind.size/batch_size),\n",
    "                      epochs=epochs,\n",
    "                      callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)],\n",
    "                      verbose=True)\n",
    "\n",
    "            preds = \\\n",
    "            model_nn.predict([xx[inner_test_ind] for xx in train_aux_dat],\n",
    "                             batch_size=1024)\n",
    "            oof_scores_sex[inner_test_ind] = \\\n",
    "                preds[0].flatten().argsort().argsort()/inner_test_ind.size\n",
    "            oof_scores_age[inner_test_ind] = preds[-1]\n",
    "        # сохраняем для каждого фолда свои oof скоры, чтобы избежать утечки таргета\n",
    "        os.makedirs('oof_scores_260223/%d'%RANDOM_SEED, exist_ok=True)\n",
    "        with gzip.open('oof_scores_260223/%d/%d.pickle.gz'%(RANDOM_SEED, K), 'wb') as f:\n",
    "            pickle.dump(dict(sex=oof_scores_sex, age=oof_scores_age, fold=K),\n",
    "                        f,\n",
    "                        protocol=-1)\n",
    "        K += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение oof скоров по каждому фолду для будущей self-distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age_extra_dim': 22, 'age_weight': 1.8, 'base_lr': 0.0017782794100389228, 'batch_size': 256, 'dense_size': 2048, 'e_cbag': 362, 'e_clip': 1, 'e_cpeman': 53, 'e_cpemodname': 1, 'e_cpetype': 8, 'e_price': 38, 'emb_size': 11, 'epochs': 3, 'factor': 1.25, 'offset': -0.5, 'sex_weight': 1.5, 'steps_subsample': 1.0, 'use_feats': (1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbba47bbdd6e4539ab8db8f216a3033b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcc1e28dcfa443f967b0eefd4e161c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80b1343bf36453eb9ca73d250f7ced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_793/dense_5551/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_793/dense_5551/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_793/dense_5551/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_793/dense_5554/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_793/dense_5554/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_793/dense_5554/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_793/dense_5553/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_793/dense_5553/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_793/dense_5553/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 54ms/step - loss: 3.0841 - sex_loss: 0.4747 - age_loss: 1.2952\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6926 - sex_loss: 0.4049 - age_loss: 1.1360\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6233 - sex_loss: 0.3925 - age_loss: 1.1079\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_794/dense_5558/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_794/dense_5558/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_794/dense_5558/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_794/dense_5561/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_794/dense_5561/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_794/dense_5561/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_794/dense_5560/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_794/dense_5560/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_794/dense_5560/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 53ms/step - loss: 3.0718 - sex_loss: 0.4693 - age_loss: 1.2924\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6885 - sex_loss: 0.4016 - age_loss: 1.1359\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 44s 54ms/step - loss: 2.6185 - sex_loss: 0.3876 - age_loss: 1.1088\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_795/dense_5565/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_795/dense_5565/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_795/dense_5565/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_795/dense_5568/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_795/dense_5568/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_795/dense_5568/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_795/dense_5567/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_795/dense_5567/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_795/dense_5567/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 53ms/step - loss: 3.0860 - sex_loss: 0.4758 - age_loss: 1.2954\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6906 - sex_loss: 0.4045 - age_loss: 1.1351\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6214 - sex_loss: 0.3916 - age_loss: 1.1074\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_796/dense_5572/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_796/dense_5572/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_796/dense_5572/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_796/dense_5575/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_796/dense_5575/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_796/dense_5575/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_796/dense_5574/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_796/dense_5574/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_796/dense_5574/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0937 - sex_loss: 0.4740 - age_loss: 1.3015\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6997 - sex_loss: 0.4049 - age_loss: 1.1406\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6361 - sex_loss: 0.3928 - age_loss: 1.1153\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_797/dense_5579/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_797/dense_5579/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_797/dense_5579/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_797/dense_5582/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_797/dense_5582/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_797/dense_5582/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_797/dense_5581/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_797/dense_5581/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_797/dense_5581/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0809 - sex_loss: 0.4701 - age_loss: 1.2977\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6974 - sex_loss: 0.4051 - age_loss: 1.1391\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6320 - sex_loss: 0.3925 - age_loss: 1.1134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da859bf555204ad8ae3bd1dcb50d04c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_798/dense_5586/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_798/dense_5586/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_798/dense_5586/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_798/dense_5589/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_798/dense_5589/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_798/dense_5589/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_798/dense_5588/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_798/dense_5588/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_798/dense_5588/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 52ms/step - loss: 3.0766 - sex_loss: 0.4710 - age_loss: 1.2934\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 53ms/step - loss: 2.6871 - sex_loss: 0.4030 - age_loss: 1.1336\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6168 - sex_loss: 0.3898 - age_loss: 1.1057\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_799/dense_5593/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_799/dense_5593/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_799/dense_5593/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_799/dense_5596/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_799/dense_5596/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_799/dense_5596/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_799/dense_5595/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_799/dense_5595/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_799/dense_5595/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 48s 52ms/step - loss: 3.0785 - sex_loss: 0.4717 - age_loss: 1.2939\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6912 - sex_loss: 0.4042 - age_loss: 1.1348\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 44s 54ms/step - loss: 2.6203 - sex_loss: 0.3910 - age_loss: 1.1065\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_800/dense_5600/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_800/dense_5600/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_800/dense_5600/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_800/dense_5603/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_800/dense_5603/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_800/dense_5603/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_800/dense_5602/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_800/dense_5602/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_800/dense_5602/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 48s 55ms/step - loss: 3.0789 - sex_loss: 0.4693 - age_loss: 1.2963\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 44s 53ms/step - loss: 2.6856 - sex_loss: 0.4023 - age_loss: 1.1337\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6182 - sex_loss: 0.3897 - age_loss: 1.1069\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_801/dense_5607/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_801/dense_5607/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_801/dense_5607/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_801/dense_5610/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_801/dense_5610/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_801/dense_5610/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_801/dense_5609/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_801/dense_5609/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_801/dense_5609/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0876 - sex_loss: 0.4759 - age_loss: 1.2961\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6881 - sex_loss: 0.4036 - age_loss: 1.1344\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 44s 53ms/step - loss: 2.6203 - sex_loss: 0.3913 - age_loss: 1.1070\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_802/dense_5614/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_802/dense_5614/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_802/dense_5614/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_802/dense_5617/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_802/dense_5617/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_802/dense_5617/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_802/dense_5616/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_802/dense_5616/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_802/dense_5616/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0822 - sex_loss: 0.4734 - age_loss: 1.2950\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6943 - sex_loss: 0.4051 - age_loss: 1.1364\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6262 - sex_loss: 0.3921 - age_loss: 1.1095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9222365401a9448e9866ada2733129d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_803/dense_5621/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_803/dense_5621/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_803/dense_5621/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_803/dense_5624/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_803/dense_5624/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_803/dense_5624/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_803/dense_5623/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_803/dense_5623/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_803/dense_5623/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 48s 53ms/step - loss: 3.0958 - sex_loss: 0.4782 - age_loss: 1.2992\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 44s 53ms/step - loss: 2.6996 - sex_loss: 0.4077 - age_loss: 1.1381\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6352 - sex_loss: 0.3955 - age_loss: 1.1125\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_804/dense_5628/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_804/dense_5628/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_804/dense_5628/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_804/dense_5631/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_804/dense_5631/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_804/dense_5631/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_804/dense_5630/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_804/dense_5630/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_804/dense_5630/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 53ms/step - loss: 3.0836 - sex_loss: 0.4809 - age_loss: 1.2895\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6950 - sex_loss: 0.4060 - age_loss: 1.1361\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 44s 54ms/step - loss: 2.6269 - sex_loss: 0.3936 - age_loss: 1.1087\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_805/dense_5635/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_805/dense_5635/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_805/dense_5635/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_805/dense_5638/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_805/dense_5638/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_805/dense_5638/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_805/dense_5637/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_805/dense_5637/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_805/dense_5637/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 54ms/step - loss: 3.0919 - sex_loss: 0.4712 - age_loss: 1.3027\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 54ms/step - loss: 2.6972 - sex_loss: 0.4035 - age_loss: 1.1402\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6307 - sex_loss: 0.3904 - age_loss: 1.1142\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_806/dense_5642/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_806/dense_5642/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_806/dense_5642/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_806/dense_5645/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_806/dense_5645/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_806/dense_5645/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_806/dense_5644/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_806/dense_5644/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_806/dense_5644/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 48s 54ms/step - loss: 3.0873 - sex_loss: 0.4728 - age_loss: 1.2979\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6909 - sex_loss: 0.4053 - age_loss: 1.1339\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6207 - sex_loss: 0.3923 - age_loss: 1.1058\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_807/dense_5649/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_807/dense_5649/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_807/dense_5649/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_807/dense_5652/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_807/dense_5652/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_807/dense_5652/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_807/dense_5651/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_807/dense_5651/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_807/dense_5651/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0814 - sex_loss: 0.4748 - age_loss: 1.2929\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6924 - sex_loss: 0.4035 - age_loss: 1.1361\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6219 - sex_loss: 0.3905 - age_loss: 1.1078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7fddbe06a0454da3a931aac8003b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_808/dense_5656/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_808/dense_5656/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_808/dense_5656/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_808/dense_5659/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_808/dense_5659/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_808/dense_5659/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_808/dense_5658/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_808/dense_5658/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_808/dense_5658/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 45s 53ms/step - loss: 3.0628 - sex_loss: 0.4755 - age_loss: 1.2824\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6921 - sex_loss: 0.4044 - age_loss: 1.1358\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6236 - sex_loss: 0.3914 - age_loss: 1.1086\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_809/dense_5663/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_809/dense_5663/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_809/dense_5663/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_809/dense_5666/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_809/dense_5666/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_809/dense_5666/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_809/dense_5665/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_809/dense_5665/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_809/dense_5665/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 45s 52ms/step - loss: 3.0944 - sex_loss: 0.4753 - age_loss: 1.3007\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 41s 51ms/step - loss: 2.7049 - sex_loss: 0.4080 - age_loss: 1.1408\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6399 - sex_loss: 0.3958 - age_loss: 1.1149\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_810/dense_5670/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_810/dense_5670/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_810/dense_5670/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_810/dense_5673/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_810/dense_5673/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_810/dense_5673/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_810/dense_5672/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_810/dense_5672/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_810/dense_5672/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 48s 52ms/step - loss: 3.0899 - sex_loss: 0.4686 - age_loss: 1.3035\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6966 - sex_loss: 0.4040 - age_loss: 1.1392\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6307 - sex_loss: 0.3912 - age_loss: 1.1132\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_811/dense_5677/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_811/dense_5677/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_811/dense_5677/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_811/dense_5680/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_811/dense_5680/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_811/dense_5680/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_811/dense_5679/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_811/dense_5679/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_811/dense_5679/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0776 - sex_loss: 0.4708 - age_loss: 1.2942\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6883 - sex_loss: 0.4036 - age_loss: 1.1339\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6159 - sex_loss: 0.3899 - age_loss: 1.1051\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_812/dense_5684/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_812/dense_5684/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_812/dense_5684/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_812/dense_5687/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_812/dense_5687/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_812/dense_5687/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_812/dense_5686/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_812/dense_5686/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_812/dense_5686/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 52ms/step - loss: 3.0834 - sex_loss: 0.4738 - age_loss: 1.2953\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 51ms/step - loss: 2.6909 - sex_loss: 0.4050 - age_loss: 1.1347\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6197 - sex_loss: 0.3916 - age_loss: 1.1064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077e20dda5114e64b17855d2c0fcd2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_813/dense_5691/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_813/dense_5691/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_813/dense_5691/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_813/dense_5694/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_813/dense_5694/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_813/dense_5694/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_813/dense_5693/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_813/dense_5693/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_813/dense_5693/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 52ms/step - loss: 3.0795 - sex_loss: 0.4730 - age_loss: 1.2941\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6966 - sex_loss: 0.4045 - age_loss: 1.1385\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6288 - sex_loss: 0.3922 - age_loss: 1.1112\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_814/dense_5698/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_814/dense_5698/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_814/dense_5698/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_814/dense_5701/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_814/dense_5701/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_814/dense_5701/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_814/dense_5700/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_814/dense_5700/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_814/dense_5700/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 45s 52ms/step - loss: 3.0756 - sex_loss: 0.4679 - age_loss: 1.2954\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6880 - sex_loss: 0.4024 - age_loss: 1.1347\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6184 - sex_loss: 0.3887 - age_loss: 1.1075\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_815/dense_5705/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_815/dense_5705/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_815/dense_5705/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_815/dense_5708/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_815/dense_5708/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_815/dense_5708/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_815/dense_5707/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_815/dense_5707/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_815/dense_5707/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 45s 51ms/step - loss: 3.0812 - sex_loss: 0.4773 - age_loss: 1.2916\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.7008 - sex_loss: 0.4053 - age_loss: 1.1406\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6365 - sex_loss: 0.3929 - age_loss: 1.1153\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_816/dense_5712/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_816/dense_5712/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_816/dense_5712/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_816/dense_5715/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_816/dense_5715/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_816/dense_5715/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_816/dense_5714/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_816/dense_5714/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_816/dense_5714/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 53ms/step - loss: 3.0953 - sex_loss: 0.4760 - age_loss: 1.3008\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.7005 - sex_loss: 0.4061 - age_loss: 1.1399\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6348 - sex_loss: 0.3936 - age_loss: 1.1139\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_817/dense_5719/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_817/dense_5719/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_817/dense_5719/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_817/dense_5722/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_817/dense_5722/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_817/dense_5722/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_817/dense_5721/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_817/dense_5721/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_817/dense_5721/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 49s 53ms/step - loss: 3.0787 - sex_loss: 0.4721 - age_loss: 1.2937\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6863 - sex_loss: 0.4036 - age_loss: 1.1327\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 53ms/step - loss: 2.6145 - sex_loss: 0.3902 - age_loss: 1.1041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f5eedcfcb9471d90d575f9cd3c112c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_818/dense_5726/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_818/dense_5726/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_818/dense_5726/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_818/dense_5729/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_818/dense_5729/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_818/dense_5729/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_818/dense_5728/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_818/dense_5728/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_818/dense_5728/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0805 - sex_loss: 0.4752 - age_loss: 1.2923\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 45s 52ms/step - loss: 3.0702 - sex_loss: 0.4701 - age_loss: 1.2902\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6856 - sex_loss: 0.4012 - age_loss: 1.1337\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6133 - sex_loss: 0.3874 - age_loss: 1.1052\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_820/dense_5740/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_820/dense_5740/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_820/dense_5740/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_820/dense_5743/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_820/dense_5743/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_820/dense_5743/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_820/dense_5742/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_820/dense_5742/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_820/dense_5742/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 47s 52ms/step - loss: 3.0833 - sex_loss: 0.4722 - age_loss: 1.2962\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6881 - sex_loss: 0.4039 - age_loss: 1.1336\n",
      "Epoch 3/3\n",
      "437/759 [================>.............] - ETA: 16s - loss: 2.6143 - sex_loss: 0.3895 - age_loss: 1.1047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6301 - sex_loss: 0.3927 - age_loss: 1.1120\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_824/dense_5768/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_824/dense_5768/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_824/dense_5768/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_824/dense_5771/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_824/dense_5771/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_824/dense_5771/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_824/dense_5770/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_824/dense_5770/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_824/dense_5770/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 49s 53ms/step - loss: 3.1006 - sex_loss: 0.4714 - age_loss: 1.3071\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6922 - sex_loss: 0.4040 - age_loss: 1.1366\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6267 - sex_loss: 0.3913 - age_loss: 1.1109\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_825/dense_5775/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_825/dense_5775/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_825/dense_5775/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_825/dense_5778/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_825/dense_5778/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_825/dense_5778/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_825/dense_5777/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_825/dense_5777/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_825/dense_5777/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 45s 52ms/step - loss: 3.0914 - sex_loss: 0.4734 - age_loss: 1.3002\n",
      "Epoch 2/3\n",
      "270/759 [=========>....................] - ETA: 25s - loss: 2.7265 - sex_loss: 0.4123 - age_loss: 1.1484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6281 - sex_loss: 0.3944 - age_loss: 1.1085\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_829/dense_5803/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_829/dense_5803/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_829/dense_5803/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_829/dense_5806/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_829/dense_5806/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_829/dense_5806/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_829/dense_5805/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_829/dense_5805/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_829/dense_5805/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0730 - sex_loss: 0.4720 - age_loss: 1.2910\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6902 - sex_loss: 0.4042 - age_loss: 1.1348\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6190 - sex_loss: 0.3906 - age_loss: 1.1067\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_830/dense_5810/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_830/dense_5810/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_830/dense_5810/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_830/dense_5813/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_830/dense_5813/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_830/dense_5813/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_830/dense_5812/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_830/dense_5812/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_830/dense_5812/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0784 - sex_loss: 0.4748 - age_loss: 1.2916\n",
      "Epoch 2/3\n",
      " 80/759 [==>...........................] - ETA: 37s - loss: 2.7625 - sex_loss: 0.4204 - age_loss: 1.1613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 48s 52ms/step - loss: 3.0864 - sex_loss: 0.4740 - age_loss: 1.2966\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6914 - sex_loss: 0.4046 - age_loss: 1.1350\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 42s 52ms/step - loss: 2.6205 - sex_loss: 0.3910 - age_loss: 1.1070\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_835/dense_5845/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_835/dense_5845/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_835/dense_5845/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_835/dense_5848/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_835/dense_5848/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_835/dense_5848/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_835/dense_5847/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_835/dense_5847/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_835/dense_5847/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 45s 51ms/step - loss: 3.0932 - sex_loss: 0.4721 - age_loss: 1.3026\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 41s 51ms/step - loss: 2.6990 - sex_loss: 0.4057 - age_loss: 1.1392\n",
      "Epoch 3/3\n",
      "524/759 [===================>..........] - ETA: 12s - loss: 2.6309 - sex_loss: 0.3926 - age_loss: 1.1124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 44s 53ms/step - loss: 2.7006 - sex_loss: 0.4078 - age_loss: 1.1379\n",
      "Epoch 3/3\n",
      "759/759 [==============================] - 43s 52ms/step - loss: 2.6354 - sex_loss: 0.3955 - age_loss: 1.1120\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_840/dense_5880/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_840/dense_5880/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_840/dense_5880/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_840/dense_5883/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_840/dense_5883/embedding_lookup_sparse/Reshape:0\", shape=(None, 22), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_840/dense_5883/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/data/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_840/dense_5882/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_840/dense_5882/embedding_lookup_sparse/Reshape:0\", shape=(None, 362), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_840/dense_5882/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 46s 53ms/step - loss: 3.0821 - sex_loss: 0.4750 - age_loss: 1.2936\n",
      "Epoch 2/3\n",
      "759/759 [==============================] - 42s 53ms/step - loss: 2.6891 - sex_loss: 0.4024 - age_loss: 1.1358\n",
      "Epoch 3/3\n",
      "515/759 [===================>..........] - ETA: 12s - loss: 2.6209 - sex_loss: 0.3894 - age_loss: 1.1088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# нужно выполнить два раза для двух наборов фолдов\n",
    "# 42 - model assessement фолды, 101010 - model selection фолды\n",
    "for RANDOM_SEED in [42, 101010]:\n",
    "    kfold = StratifiedKFold(n_splits=10,\n",
    "                            shuffle=True,\n",
    "                            random_state=RANDOM_SEED)\n",
    "    folds = [(train_ind, test_ind) for train_ind, test_ind in\n",
    "             kfold.split((np.uint8(trg_sex*2)+y_all*10).astype(str),\n",
    "                         (np.uint8(trg_sex*2)+y_all*10).astype(str))]\n",
    "    get_oof_score(model_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
